{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-27T11:53:42.156236Z",
     "start_time": "2024-06-27T11:53:41.920449Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import spatial \n",
    "import faiss\n",
    "import typing\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# constants\n",
    "k = 5"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "62f09c59a02a3b0d",
   "metadata": {},
   "source": "## Helper Function"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67518a644a21072d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T11:53:42.162223Z",
     "start_time": "2024-06-27T11:53:42.157304Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_vectors(\n",
    "        num_vectors: int,\n",
    "        dim: int,\n",
    "        #distribution: str,\n",
    "        seed: int = 42,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This function generates random vectors of uniform distribution.\n",
    "    Args:\n",
    "        num_vectors: The number of vectors to generate.\n",
    "        dim: The dimensionality of the vectors.\n",
    "        seed: The random seed.\n",
    "    Returns:\n",
    "        An array of shape (num_vectors, dim) containing the generated vectors.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    return np.random.uniform(0, 1, (num_vectors, dim)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3e51f57a0ae70fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T11:53:42.168722Z",
     "start_time": "2024-06-27T11:53:42.163312Z"
    }
   },
   "outputs": [],
   "source": [
    "def naive_exhaustive_search(\n",
    "        query_vectors: np.ndarray,\n",
    "        index_vectors: np.ndarray, \n",
    "        k: int,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This function computes the k-nearest neighbors of query_vectors in index_vectors using the naive exhaustive approach.\n",
    "    Args:\n",
    "        query_vectors: An array of shape (n_queries, dim) containing the query vectors. \n",
    "        index_vectors: An array of shape (n_index, dim) containing the index vectors.\n",
    "        k: The number of nearest neighbors to retrieve.\n",
    "    Returns:\n",
    "        An array of shape (n_queries, k) containing the indices of the k-nearest neighbors for each query vector.\n",
    "    \"\"\"\n",
    "    all_distances = []\n",
    "    for query_vector in query_vectors:\n",
    "        query_distances = []\n",
    "        for index_vector in index_vectors:\n",
    "            query_distances.append(spatial.distance.euclidean(query_vector, index_vector))\n",
    "        all_distances.append(np.argsort(query_distances)[:k])\n",
    "    return np.array(all_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5e56a8007517ef4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T11:53:42.175645Z",
     "start_time": "2024-06-27T11:53:42.169841Z"
    }
   },
   "outputs": [],
   "source": [
    "def optimized_exhaustive_search(\n",
    "        query_vectors: np.ndarray,\n",
    "        index_vectors: np.ndarray,\n",
    "        k: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function computes the k-nearest neighbors of query_vectors in index_vectors using the optimized exhaustive approach implemented in SciPy.\n",
    "    Args:\n",
    "        query_vectors: An array of shape (n_queries, dim) containing the query vectors. \n",
    "        index_vectors: An array of shape (n_index, dim) containing the index vectors.\n",
    "        k: The number of nearest neighbors to retrieve.\n",
    "    Returns:\n",
    "        An array of shape (n_queries, k) containing the indices of the k-nearest neighbors for each query vector.\n",
    "    \"\"\"\n",
    "    distances = spatial.distance.cdist(query_vectors, index_vectors, 'euclidean')\n",
    "    return np.argsort(distances, axis=1)[:, :k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8ef475c717fbe2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T11:53:42.180555Z",
     "start_time": "2024-06-27T11:53:42.176729Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_faiss_flatl2_index(\n",
    "        index_vectors: np.ndarray,\n",
    "        dim: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function builds a Faiss flat L2 index.\n",
    "    Args:\n",
    "        index_vectors: An array of shape (n_index, dim) containing the index vectors.\n",
    "        dim: The dimensionality of the vectors. \n",
    "    Returns:\n",
    "        A Faiss flat L2 index.\n",
    "    \"\"\"\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(index_vectors)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1df7a2d698755a82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T11:53:42.185627Z",
     "start_time": "2024-06-27T11:53:42.181384Z"
    }
   },
   "outputs": [],
   "source": [
    "def faiss_search(\n",
    "        query_vectors: np.ndarray,\n",
    "        index: faiss.Index,\n",
    "        k: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function uses a Faiss index to search for the k-nearest neighbors of query_vectors.\n",
    "    Args:\n",
    "        query_vectors: An array of shape (n_queries, dim) containing the query vectors. \n",
    "        index: A Faiss index.\n",
    "        k: The number of nearest neighbors to retrieve.\n",
    "    Returns:\n",
    "        An array of shape (n_queries, k) containing the indices of the k-nearest neighbors for each query vector.\n",
    "    \"\"\"\n",
    "    distances, indices = index.search(query_vectors, k)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af14bea64023a3d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T11:53:42.191016Z",
     "start_time": "2024-06-27T11:53:42.186705Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_faiss_lsh_index(\n",
    "        index_vectors: np.ndarray,\n",
    "        dim: int,\n",
    "        nbits: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function builds a Faiss LSH index.\n",
    "    Args:\n",
    "        index_vectors: An array of shape (n_index, dim) containing the index vectors.\n",
    "        dim: The dimensionality of the vectors. \n",
    "        nbits: The number of bits to use in the hash.\n",
    "    Returns:\n",
    "        A Faiss LSH index.\n",
    "    \"\"\"\n",
    "    index = faiss.IndexLSH(dim, nbits)\n",
    "    index.add(index_vectors)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4b0932dfa7d7a4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T11:53:42.196842Z",
     "start_time": "2024-06-27T11:53:42.192075Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_recall_at_k(\n",
    "        nn_gt: np.ndarray,\n",
    "        ann: np.ndarray,\n",
    "        k: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function computes the recall@k.\n",
    "    Args:\n",
    "        nn_gt: The ground truth nearest neighbors.\n",
    "        ann: The approximate nearest neighbors.\n",
    "        k: The number of nearest neighbors to consider.\n",
    "    Returns:\n",
    "        The recall@k.\n",
    "    \"\"\"\n",
    "    return round(sum([len(set(ann[i]) & set(nn_gt[i])) / k for i in range(len(ann))])/len(ann), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d4be2e90ed842",
   "metadata": {},
   "source": [
    "# 1.1 - Running Time Comparison\n",
    "\n",
    "You are given three methods for vector search:\n",
    "<ol>\n",
    " <li> naive_exhaustive_search </li> \n",
    " <li> optimized_exhaustive_search </li> \n",
    " <li> faiss_flatL2 </li> \n",
    "</ol>\n",
    "\n",
    "each one implements vector search with different levels of optimization. Your task is to compare the running time of these three methods. \n",
    "You need to complete the code so that the generated plots should reflect the increasing difference in running time between the methods, as a function of the desired parameters.\n",
    "The plots should be clear and self-explanatory, including the labels, title, and legend.\n",
    "There is no need to experiment with long running times (few seconds are enough for each plot); just ensure that the trends are visible.\n",
    "You are allowed to add more cells between the TODOs, but do not flip the order of the subsections.\n",
    "When you finish. do not forget to attach the plots to report.pdf, placed under a clear title indicating the section number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837db120f597a563",
   "metadata": {},
   "source": [
    "### Generate the following plots:\n",
    "##### 1.1.1. Running time of the three methods as a function of the number of vectors in the index (x-axis) with the following parameters fixed:\n",
    "* vector dimensionality: 100\n",
    "* number of vectors in the query set: 1000\n",
    "##### 1.1.2. Running time of the three methods as a function of the dimensionality of the vectors (x-axis) with the following parameters fixed:\n",
    "* number of vectors in the index: 100000\n",
    "* number of vectors in the query set: 1000"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# section 1.1.1\n",
    "vectors = generate_vectors(1500, 100)\n",
    "query_vec = vectors[:1000] # first 1000 vectors are query vectors\n",
    "data_vectors = vectors[1000:] # the rest (500) are the index\n",
    "\n",
    "index_size = [10, 50, 100, 250, 500]\n",
    "n_options = len(index_size)\n",
    "naive_runtime1 = []\n",
    "optim_runtime1 = []\n",
    "faiss_runtime1 = []\n",
    "\n",
    "for size in index_size:\n",
    "    print(f'Running for index Size: {size}...')\n",
    "    cur_index = data_vectors[:size]\n",
    "    flat_index = build_faiss_flatl2_index(data_vectors[:size], 100)\n",
    "    \n",
    "    start_time = time()\n",
    "    _ = naive_exhaustive_search(query_vec, cur_index, k)\n",
    "    end_time = time() - start_time\n",
    "    naive_runtime1.append(end_time)\n",
    "    \n",
    "    start_time = time()\n",
    "    _ = optimized_exhaustive_search(query_vec, cur_index, k)\n",
    "    end_time = time() - start_time\n",
    "    optim_runtime1.append(end_time)\n",
    "    \n",
    "    start_time = time()\n",
    "    _ = faiss_search(query_vec, flat_index, k)\n",
    "    end_time = time() - start_time\n",
    "    faiss_runtime1.append(end_time)\n",
    "    \n",
    "# plotting\n",
    "data1 = {\n",
    "    'Number of Vectors in Index': index_size * 3,\n",
    "    'Time (seconds)': naive_runtime1 + optim_runtime1 + faiss_runtime1, \n",
    "    'Method': ['Naive'] * n_options + ['Optimized'] * n_options + ['Faiss'] * n_options\n",
    "}\n",
    "df1 = pd.DataFrame(data1)\n",
    "\n",
    "# Create a figure with two subplots side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "# Plot on the first subplot with linear y-scale\n",
    "sns.lineplot(ax=axes[0], x='Number of Vectors in Index', y='Time (seconds)', hue='Method', data=df1)\n",
    "axes[0].set_ylabel('Time (seconds)')\n",
    "axes[0].set_title('Running Time Comparison with Linear Scale')\n",
    "\n",
    "# Plot on the second subplot with logarithmic y-scale\n",
    "sns.lineplot(ax=axes[1], x='Number of Vectors in Index', y='Time (seconds)', hue='Method', data=df1)\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].set_ylabel('Time (seconds) - Log Scale')\n",
    "axes[1].set_title('Running Time Comparison with Logarithmic Scale')\n",
    "\n",
    "# Set a common x-label\n",
    "for ax in axes:\n",
    "    ax.set_xlabel('Number of Vectors in Index')\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the figure\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "sns.lineplot(ax=axes[0], x='Number of Vectors in Index', y='Time (seconds)', hue='Method', data=df1)\n",
    "axes[0].set_ylabel('Time (seconds)', fontsize=12)\n",
    "axes[0].set_title('Running Time Comparison with Linear Scale', fontsize=12)\n",
    "\n",
    "sns.lineplot(ax=axes[1], x='Number of Vectors in Index', y='Time (seconds)', hue='Method', data=df1)\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].set_ylabel('Time (seconds) - Log Scale', fontsize=12)\n",
    "axes[1].set_title('Running Time Comparison with Logarithmic Scale', fontsize=12)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlabel('Number of Vectors in Index', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "855be324b6b7e29b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# section 1.1.2\n",
    "dims = [10, 50, 100, 250, 500]\n",
    "naive_runtime2 = []\n",
    "optim_runtime2 = []\n",
    "faiss_runtime2 = []\n",
    "\n",
    "for dim in dims:\n",
    "    curr_vectors = generate_vectors(100100, dim)\n",
    "    curr_query_vec = curr_vectors[:100]\n",
    "    curr_data_vectors = curr_vectors[100:]\n",
    "    curr_flat_index = build_faiss_flatl2_index(curr_data_vectors, dim)\n",
    "    \n",
    "    print(f'Running for dimension: {dim}...')\n",
    "    \n",
    "    # start_time = time()\n",
    "    # _ = naive_exhaustive_search(curr_query_vec, curr_data_vectors, k)\n",
    "    # end_time = time() - start_time\n",
    "    # naive_runtime2.append(end_time)\n",
    "    \n",
    "    start_time = time()\n",
    "    _ = optimized_exhaustive_search(curr_query_vec, curr_data_vectors, k)\n",
    "    end_time = time() - start_time\n",
    "    optim_runtime2.append(end_time)\n",
    "    \n",
    "    start_time = time()\n",
    "    _ = faiss_search(curr_query_vec, curr_flat_index, k)\n",
    "    end_time = time() - start_time\n",
    "    faiss_runtime2.append(end_time)\n",
    "    \n",
    "    \n",
    "# plotting\n",
    "data2 = {\n",
    "    'Dimension of Vectors': dims * 2,\n",
    "    'Time (seconds)': optim_runtime2 + faiss_runtime2,\n",
    "    'Method': ['Optimized'] * n_options + ['Faiss'] * n_options\n",
    "}\n",
    "df2 = pd.DataFrame(data2)\n",
    "plt.figure()\n",
    "sns.lineplot(x='Dimension of Vectors', y='Time (seconds)', hue='Method', data=df2)\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.title('Running Time Comparison of search methods per Vector Dimensionality')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65eb005e16542e38"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import torch\n",
    "# \n",
    "# def naive_exhaustive_search_gpu(\n",
    "#         query_vectors: np.ndarray,\n",
    "#         index_vectors: np.ndarray,\n",
    "#         k: int,\n",
    "# ) -> np.ndarray:\n",
    "#     \"\"\"\n",
    "#     This function computes the k-nearest neighbors of query_vectors in index_vectors using the naive exhaustive approach.\n",
    "#     Args:\n",
    "#         query_vectors: An array of shape (n_queries, dim) containing the query vectors.\n",
    "#         index_vectors: An array of shape (n_index, dim) containing the index vectors.\n",
    "#         k: The number of nearest neighbors to retrieve.\n",
    "#     Returns:\n",
    "#         An array of shape (n_queries, k) containing the indices of the k-nearest neighbors for each query vector.\n",
    "#     \"\"\"\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# \n",
    "#     query_vectors = torch.from_numpy(query_vectors).to(device)\n",
    "#     index_vectors = torch.from_numpy(index_vectors).to(device)\n",
    "# \n",
    "#     all_distances = []\n",
    "#     for query_vector in query_vectors:\n",
    "#         query_distances = []\n",
    "#         for index_vector in index_vectors:\n",
    "#             query_distances.append(torch.dist(query_vector, index_vector).item())\n",
    "#         all_distances.append(torch.argsort(torch.tensor(query_distances))[:k].cpu().numpy())\n",
    "#     return np.array(all_distances)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31866f26592f33a3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.2 -- Faiss LSH\n",
    "### Create the following plots:\n",
    "##### 1.2.1. Running time of Faiss LSH as a function of the number of vectors in the index (x-axis) with the following parameters fixed:\n",
    "* vector dimensionality: 100\n",
    "* number of vectors in the query set: 1000\n",
    "* nbits: 500\n",
    "\n",
    "##### 1.2.2. Running time of Faiss LSH as a function of nbits (x-axis) with the following parameters fixed:\n",
    "* vector dimensionality: 100\n",
    "* number of vectors in the query set: 1000\n",
    "* number of vectors in the index: 500000\n",
    "\n",
    "\n",
    "##### 1.2.3. recall@k of Faiss LSH as a function of nbits (x-axis) with the following parameters fixed:\n",
    "* vector dimensionality: 100\n",
    "* number of vectors in the query set: 1000\n",
    "* number of vectors in the index: 500000\n",
    "* k: 10\n",
    "\n",
    "\n",
    "You need to complete the code so that the generated plots should reflect the desired metrics as a function of the desired parameters.\n",
    "The plots should be clear and self-explanatory, including the labels, title, and legend.\n",
    "There is no need to experiment with long running times (few seconds are enough for each plot); just ensure that the trends are visible.\n",
    "You are allowed to add more cells between the TODOs, but do not flip the order of the subsections.\n",
    "When you finish. do not forget to attach the plots to report.pdf, placed under a clear title indicating the section number.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8856888f981c0dc3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# section 1.2.1\n",
    "vectors = generate_vectors(1500, 100)\n",
    "query_vec = vectors[:1000] # first 1000 vectors are query vectors\n",
    "data_vectors = vectors[1000:] # the rest (500) are the index\n",
    "\n",
    "index_size = [10, 50, 100, 250, 500]\n",
    "faiss_runtime3 = []\n",
    "\n",
    "for size in index_size:\n",
    "    print(f'Running for index Size: {size}...')\n",
    "    cur_index = data_vectors[:size]\n",
    "    lsh_index = build_faiss_lsh_index(data_vectors[:size], 100, 500)\n",
    "    start_time = time()\n",
    "    _ = faiss_search(query_vec, lsh_index, k)\n",
    "    end_time = time() - start_time\n",
    "    faiss_runtime3.append(end_time)\n",
    "    \n",
    "# plotting\n",
    "data3 = {\n",
    "    'Number of Vectors in Index': index_size,\n",
    "    'Time (seconds)': faiss_runtime3\n",
    "}\n",
    "df3 = pd.DataFrame(data3)\n",
    "plt.figure()\n",
    "sns.lineplot(x='Number of Vectors in Index', y='Time (seconds)', data=df3)\n",
    "plt.title('Running Time of Faiss LSH per Index Size')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ee8172e5a6a94bf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# section 1.2.2\n",
    "vectors = generate_vectors(501000, 100)\n",
    "query_vec = vectors[:1000] # first 1000 vectors are query vectors\n",
    "data_vectors = vectors[1000:] # the rest (50000) are the index\n",
    "\n",
    "nbits_options = [100, 250, 500, 750, 1000]\n",
    "faiss_runtime4 = []\n",
    "\n",
    "for nbit in nbits_options:\n",
    "    print(f'Running for nbits value: {nbit}...')\n",
    "    lsh_index = build_faiss_lsh_index(data_vectors, 100, nbit)\n",
    "    start_time = time()\n",
    "    _ = faiss_search(query_vec, lsh_index, k)\n",
    "    end_time = time() - start_time\n",
    "    faiss_runtime4.append(end_time)\n",
    "    \n",
    "# plotting\n",
    "data4 = {\n",
    "    'Nbits Value of the Index': nbits_options,\n",
    "    'Time (seconds)': faiss_runtime4\n",
    "}\n",
    "df4 = pd.DataFrame(data4)\n",
    "plt.figure()\n",
    "sns.lineplot(x='Nbits Value of the Index', y='Time (seconds)', data=df4)\n",
    "plt.title('Running Time of Faiss LSH per Nbits Value')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7695784898d383d0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# section 1.2.3\n",
    "fixed_k = 10\n",
    "vectors = generate_vectors(501000, 100)\n",
    "query_vec = vectors[:1000] # first 1000 vectors are query vectors\n",
    "data_vectors = vectors[1000:] # the rest (50000) are the index\n",
    "gt_neighbors = optimized_exhaustive_search(query_vec, data_vectors, fixed_k)\n",
    "print(f'Finished ground truth search...')\n",
    "\n",
    "nbits_options = [100, 250, 500, 750, 1000]\n",
    "faiss_recall = []\n",
    "for nbit in nbits_options:\n",
    "    print(f'Running for nbits value: {nbit}...')\n",
    "    lsh_index = build_faiss_lsh_index(data_vectors, 100, nbit)\n",
    "    curr_faiss_res = faiss_search(query_vec, lsh_index, fixed_k)\n",
    "    curr_recall = compute_recall_at_k(gt_neighbors, curr_faiss_res, fixed_k)\n",
    "    faiss_recall.append(curr_recall)\n",
    "    \n",
    "# plotting\n",
    "data5 = {\n",
    "    'Nbits Value of the Index': nbits_options,\n",
    "    'Recall Value': faiss_recall\n",
    "}\n",
    "df5 = pd.DataFrame(data5)\n",
    "plt.figure()\n",
    "sns.lineplot(x='Nbits Value of the Index', y='Recall Value', data=df5)\n",
    "plt.title('Recall Value of Faiss LSH per Nbits Value')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "338c9c37b98a255d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283f01e38696d48c",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
